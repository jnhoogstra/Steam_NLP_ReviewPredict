{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "###### Here I will be importing the necessary packages to use for this project. Some may not be used but could be used and I am covering my baises with them incase I do use one later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/elliott/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/elliott/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "import scipy.stats as stats\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import scipy\n",
    "\n",
    "import types\n",
    "import re\n",
    "import nltk\n",
    "import xgboost\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "import pickle\n",
    "\n",
    "from keras.preprocessing import text, sequence\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the Data\n",
    "\n",
    "###### Data cleaned by partner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steamid</th>\n",
       "      <th>appid</th>\n",
       "      <th>app_title</th>\n",
       "      <th>app_tags</th>\n",
       "      <th>review</th>\n",
       "      <th>fps</th>\n",
       "      <th>voted_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561198271088129</td>\n",
       "      <td>4000</td>\n",
       "      <td>Garry's Mod</td>\n",
       "      <td>['Sandbox', 'Multiplayer', 'Funny', 'Moddable'...</td>\n",
       "      <td>good models\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561198138206834</td>\n",
       "      <td>4000</td>\n",
       "      <td>Garry's Mod</td>\n",
       "      <td>['Sandbox', 'Multiplayer', 'Funny', 'Moddable'...</td>\n",
       "      <td>I completely suck at making anything on here a...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198128760839</td>\n",
       "      <td>70</td>\n",
       "      <td>Half-Life</td>\n",
       "      <td>['FPS', 'Sci-fi', 'Action', 'Singleplayer', \"1...</td>\n",
       "      <td>There is not much to say about this old game t...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             steamid  appid    app_title  \\\n",
       "0  76561198271088129   4000  Garry's Mod   \n",
       "1  76561198138206834   4000  Garry's Mod   \n",
       "2  76561198128760839     70    Half-Life   \n",
       "\n",
       "                                            app_tags  \\\n",
       "0  ['Sandbox', 'Multiplayer', 'Funny', 'Moddable'...   \n",
       "1  ['Sandbox', 'Multiplayer', 'Funny', 'Moddable'...   \n",
       "2  ['FPS', 'Sci-fi', 'Action', 'Singleplayer', \"1...   \n",
       "\n",
       "                                              review   fps  voted_up  \n",
       "0                                      good models\\n  True      True  \n",
       "1  I completely suck at making anything on here a...  True      True  \n",
       "2  There is not much to say about this old game t...  True      True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../data/thanos.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for use\n",
    "\n",
    "###### Functions create by teammate for use on models and to prepare the data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScoreModel(model, X, y):\n",
    "    preds = model.predict(X)\n",
    "    acc = accuracy_score(y, preds)\n",
    "    f1 = f1_score(y, preds)\n",
    "    recall = recall_score(y, preds)\n",
    "    precision = precision_score(y, preds)\n",
    "    rockout = roc_auc_score(y, preds)\n",
    "    \n",
    "    print(\"Accuracy:  \", acc)\n",
    "    print(\"F1 Score:  \", f1)\n",
    "    print(\"Recall:    \", recall)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"ROC_AUC:   \", rockout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanText(reviews):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    punct = string.punctuation\n",
    "    lemma = nltk.WordNetLemmatizer()\n",
    "    \n",
    "    reviews = \"\".join([word for word in reviews if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', reviews)\n",
    "    reviews = [lemma.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    \n",
    "    \n",
    "    return reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(reviews):\n",
    "    reviews = \"\".join([word for word in reviews if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', reviews)\n",
    "    reviews = [lemma.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Checking on the data with a .info() method in order to check the data for nulls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23183 entries, 0 to 23182\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   steamid    23183 non-null  int64 \n",
      " 1   appid      23183 non-null  int64 \n",
      " 2   app_title  23183 non-null  object\n",
      " 3   app_tags   23183 non-null  object\n",
      " 4   review     23183 non-null  object\n",
      " 5   fps        23183 non-null  bool  \n",
      " 6   voted_up   23183 non-null  bool  \n",
      "dtypes: bool(2), int64(2), object(3)\n",
      "memory usage: 951.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Looking at the percentage of the column voted_up based on value count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.505888\n",
       "False    0.494112\n",
       "Name: voted_up, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"voted_up\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using a function above to creat a new column in the data frame for use later int he notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steamid</th>\n",
       "      <th>appid</th>\n",
       "      <th>app_title</th>\n",
       "      <th>app_tags</th>\n",
       "      <th>review</th>\n",
       "      <th>fps</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561198271088129</td>\n",
       "      <td>4000</td>\n",
       "      <td>Garry's Mod</td>\n",
       "      <td>['Sandbox', 'Multiplayer', 'Funny', 'Moddable'...</td>\n",
       "      <td>good models\\n</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[good, model, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561198138206834</td>\n",
       "      <td>4000</td>\n",
       "      <td>Garry's Mod</td>\n",
       "      <td>['Sandbox', 'Multiplayer', 'Funny', 'Moddable'...</td>\n",
       "      <td>I completely suck at making anything on here a...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[completely, suck, making, anything, death, ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198128760839</td>\n",
       "      <td>70</td>\n",
       "      <td>Half-Life</td>\n",
       "      <td>['FPS', 'Sci-fi', 'Action', 'Singleplayer', \"1...</td>\n",
       "      <td>There is not much to say about this old game t...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[much, say, old, game, hasnt, said, really, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198079636858</td>\n",
       "      <td>6060</td>\n",
       "      <td>Star Wars: Battlefront 2 (Classic, 2005)</td>\n",
       "      <td>['Action', 'Multiplayer', 'Shooter', 'Third-Pe...</td>\n",
       "      <td>360 noscoped almost everything 10/10 even the ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[360, noscoped, almost, everything, 1010, even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561198238100200</td>\n",
       "      <td>220</td>\n",
       "      <td>Half-Life 2</td>\n",
       "      <td>['FPS', 'Action', 'Sci-fi', 'Classic', 'Single...</td>\n",
       "      <td>No need for a review. It's practically history.</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[need, review, practically, history]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             steamid  appid                                 app_title  \\\n",
       "0  76561198271088129   4000                               Garry's Mod   \n",
       "1  76561198138206834   4000                               Garry's Mod   \n",
       "2  76561198128760839     70                                 Half-Life   \n",
       "3  76561198079636858   6060  Star Wars: Battlefront 2 (Classic, 2005)   \n",
       "4  76561198238100200    220                               Half-Life 2   \n",
       "\n",
       "                                            app_tags  \\\n",
       "0  ['Sandbox', 'Multiplayer', 'Funny', 'Moddable'...   \n",
       "1  ['Sandbox', 'Multiplayer', 'Funny', 'Moddable'...   \n",
       "2  ['FPS', 'Sci-fi', 'Action', 'Singleplayer', \"1...   \n",
       "3  ['Action', 'Multiplayer', 'Shooter', 'Third-Pe...   \n",
       "4  ['FPS', 'Action', 'Sci-fi', 'Classic', 'Single...   \n",
       "\n",
       "                                              review   fps  voted_up  \\\n",
       "0                                      good models\\n  True      True   \n",
       "1  I completely suck at making anything on here a...  True      True   \n",
       "2  There is not much to say about this old game t...  True      True   \n",
       "3  360 noscoped almost everything 10/10 even the ...  True      True   \n",
       "4    No need for a review. It's practically history.  True      True   \n",
       "\n",
       "                                        clean_review  \n",
       "0                                    [good, model, ]  \n",
       "1  [completely, suck, making, anything, death, ru...  \n",
       "2  [much, say, old, game, hasnt, said, really, ma...  \n",
       "3  [360, noscoped, almost, everything, 1010, even...  \n",
       "4               [need, review, practically, history]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_review'] = df['review'].apply(lambda x: CleanText(x.lower()))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of the preprocessing \n",
    "Vectorizing and train test splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.4 s ± 250 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "vector = TfidfVectorizer(analyzer=CleanText, ngram_range=(2, 2))\n",
    "X = vector.fit_transform(df[\"review\"])\n",
    "\n",
    "X_df = pd.DataFrame(X.toarray())\n",
    "X_df.columns = vector.get_feature_names()\n",
    "X_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=<function CleanText at 0x7f8271a90790>,\n",
       "                ngram_range=(2, 2))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_pikl=vector.fit(df['review'])\n",
    "vector_pikl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"voted_up\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, random_state=57, test_size = 0.5,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model\n",
    "\n",
    "Using a simple logistic regression model as the baseling model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.912173237856958\n",
      "F1 Score:   0.9129765771926825\n",
      "Recall:     0.9106412005457026\n",
      "Precision:  0.9153239629756599\n",
      "ROC_AUC:    0.9121915623821581\n"
     ]
    }
   ],
   "source": [
    "baseline = LogisticRegression()\n",
    "baseline.fit(X_train, y_train)\n",
    "ScoreModel(baseline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.814095928226363\n",
      "F1 Score:   0.8169229462237703\n",
      "Recall:     0.819918144611187\n",
      "Precision:  0.813949551379719\n",
      "ROC_AUC:    0.814026809735761\n"
     ]
    }
   ],
   "source": [
    "ScoreModel(baseline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline results \n",
    "\n",
    "Results where decent not great so we try a MultinomialNB model now to check the score diffrences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultinomialNB Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.90156155637995\n",
      "F1 Score:   0.8981704596162428\n",
      "Recall:     0.8581173260572987\n",
      "Precision:  0.9421456656056918\n",
      "ROC_AUC:    0.9020811879107866\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "ScoreModel(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.7979641131815045\n",
      "F1 Score:   0.7863918278000729\n",
      "Recall:     0.7351637107776262\n",
      "Precision:  0.8452941176470589\n",
      "ROC_AUC:    0.7987096486849025\n"
     ]
    }
   ],
   "source": [
    "ScoreModel(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Results where better than the baseline we will now try one more Multinomial model with a one parameter grid search to test the scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting a Grid Search MultinomialNB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha': [.05,0.5, 1, 1.5, 2],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': [0.05, 0.5, 1, 1.5, 2]}, scoring='accuracy')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = MultinomialNB()\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "clf_gs = GridSearchCV(estimator=clf2, param_grid=param_grid, scoring='accuracy')\n",
    "clf_gs.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = clf_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.5}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.9197653351738417\n",
      "F1 Score:   0.9184067380242147\n",
      "Recall:     0.8925648021828103\n",
      "Precision:  0.9457896638959161\n",
      "ROC_AUC:    0.9200906776760045\n"
     ]
    }
   ],
   "source": [
    "ScoreModel(clf_gs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.8019323671497585\n",
      "F1 Score:   0.794522999821013\n",
      "Recall:     0.7569918144611187\n",
      "Precision:  0.835969868173258\n",
      "ROC_AUC:    0.8024658792975985\n"
     ]
    }
   ],
   "source": [
    "ScoreModel(clf_gs, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of Grid Search\n",
    "The results were similar but took substanially longer with no true diffrence in scores. Causing us to choose the first MultinomialNB model as our final model. Below we pickled our model in order to deploy the model on a application along with the reccomendation side of the project.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nlp_model.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vector_fit.pkl', 'wb') as f:\n",
    "    pickle.dump(vector_pikl, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
